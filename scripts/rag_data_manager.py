#!/usr/bin/env python3
"""
RAGæ•°æ®ç®¡ç†è„šæœ¬
ç”¨äºç®¡ç†Qdrantå‘é‡æ•°æ®åº“ä¸­çš„æ•°æ®
"""
import os
import sys
import asyncio
import argparse
from pathlib import Path
from typing import List, Dict, Any
import json
from loguru import logger

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from app.core.config import get_settings
from app.repositories.rag_repository import QdrantRepository


class RAGDataManager:
    """RAGæ•°æ®ç®¡ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç®¡ç†å™¨"""
        self.settings = get_settings()
        self.qdrant_repo = QdrantRepository(self.settings)
    
    async def list_collections(self) -> List[Dict[str, Any]]:
        """åˆ—å‡ºæ‰€æœ‰é›†åˆ"""
        try:
            collections = await self.qdrant_repo.get_collections()
            
            logger.info("ğŸ“‹ é›†åˆåˆ—è¡¨:")
            logger.info("-" * 60)
            
            if not collections:
                logger.info("æš‚æ— é›†åˆ")
                return []
            
            collection_data = []
            for collection in collections:
                data = {
                    "name": collection.name,
                    "vectors_count": collection.vectors_count,
                    "indexed_only": collection.indexed_only
                }
                collection_data.append(data)
                
                logger.info(f"é›†åˆåç§°: {collection.name}")
                logger.info(f"å‘é‡æ•°é‡: {collection.vectors_count}")
                logger.info(f"ä»…ç´¢å¼•: {collection.indexed_only}")
                logger.info("-" * 60)
            
            return collection_data
        
        except Exception as e:
            logger.error(f"è·å–é›†åˆåˆ—è¡¨å¤±è´¥: {e}")
            raise
    
    async def delete_collection(self, collection_name: str) -> bool:
        """åˆ é™¤é›†åˆ"""
        try:
            logger.info(f"å‡†å¤‡åˆ é™¤é›†åˆ: {collection_name}")
            
            # ç¡®è®¤åˆ é™¤
            confirm = input(f"ç¡®è®¤åˆ é™¤é›†åˆ '{collection_name}' å—ï¼Ÿè¿™å°†åˆ é™¤æ‰€æœ‰æ•°æ®ï¼(y/N): ")
            if confirm.lower() != 'y':
                logger.info("å–æ¶ˆåˆ é™¤æ“ä½œ")
                return False
            
            success = await self.qdrant_repo.delete_collection(collection_name)
            
            if success:
                logger.info(f"âœ… é›†åˆ {collection_name} åˆ é™¤æˆåŠŸ")
            else:
                logger.error(f"âŒ é›†åˆ {collection_name} åˆ é™¤å¤±è´¥")
            
            return success
        
        except Exception as e:
            logger.error(f"åˆ é™¤é›†åˆå¤±è´¥: {e}")
            raise
    
    async def get_collection_info(self, collection_name: str) -> Dict[str, Any]:
        """è·å–é›†åˆè¯¦ç»†ä¿¡æ¯"""
        try:
            collection_info = await self.qdrant_repo.get_collection_info(collection_name)
            
            if not collection_info:
                logger.error(f"é›†åˆ {collection_name} ä¸å­˜åœ¨")
                return {}
            
            logger.info(f"ğŸ“Š é›†åˆ {collection_name} è¯¦ç»†ä¿¡æ¯:")
            logger.info("-" * 60)
            logger.info(f"åç§°: {collection_info.name}")
            logger.info(f"å‘é‡æ•°é‡: {collection_info.vectors_count}")
            logger.info(f"ä»…ç´¢å¼•: {collection_info.indexed_only}")
            
            if collection_info.payload_schema:
                logger.info("è½½è·æ¨¡å¼:")
                for key, value in collection_info.payload_schema.items():
                    logger.info(f"  {key}: {value}")
            
            return {
                "name": collection_info.name,
                "vectors_count": collection_info.vectors_count,
                "indexed_only": collection_info.indexed_only,
                "payload_schema": collection_info.payload_schema
            }
        
        except Exception as e:
            logger.error(f"è·å–é›†åˆä¿¡æ¯å¤±è´¥: {e}")
            raise
    
    async def backup_collection_info(self, output_file: str = None) -> str:
        """å¤‡ä»½é›†åˆä¿¡æ¯åˆ°JSONæ–‡ä»¶"""
        try:
            collections = await self.qdrant_repo.get_collections()
            
            backup_data = {
                "timestamp": str(asyncio.get_event_loop().time()),
                "collections": []
            }
            
            for collection in collections:
                collection_data = {
                    "name": collection.name,
                    "vectors_count": collection.vectors_count,
                    "indexed_only": collection.indexed_only,
                    "payload_schema": collection.payload_schema
                }
                backup_data["collections"].append(collection_data)
            
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            if not output_file:
                from datetime import datetime
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                output_file = f"qdrant_backup_{timestamp}.json"
            
            # å†™å…¥æ–‡ä»¶
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(backup_data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"âœ… é›†åˆä¿¡æ¯å·²å¤‡ä»½åˆ°: {output_file}")
            return output_file
        
        except Exception as e:
            logger.error(f"å¤‡ä»½é›†åˆä¿¡æ¯å¤±è´¥: {e}")
            raise
    
    async def create_collection(
        self, 
        collection_name: str, 
        vector_size: int = 1536
    ) -> bool:
        """åˆ›å»ºæ–°é›†åˆ"""
        try:
            logger.info(f"åˆ›å»ºé›†åˆ: {collection_name}")
            logger.info(f"å‘é‡ç»´åº¦: {vector_size}")
            
            success = await self.qdrant_repo.create_collection(
                collection_name=collection_name,
                vector_size=vector_size
            )
            
            if success:
                logger.info(f"âœ… é›†åˆ {collection_name} åˆ›å»ºæˆåŠŸ")
            else:
                logger.error(f"âŒ é›†åˆ {collection_name} åˆ›å»ºå¤±è´¥")
            
            return success
        
        except Exception as e:
            logger.error(f"åˆ›å»ºé›†åˆå¤±è´¥: {e}")
            raise
    
    async def count_vectors(self, collection_name: str) -> int:
        """ç»Ÿè®¡é›†åˆä¸­çš„å‘é‡æ•°é‡"""
        try:
            count = await self.qdrant_repo.count_points(collection_name)
            logger.info(f"é›†åˆ {collection_name} åŒ…å« {count} ä¸ªå‘é‡")
            return count
        
        except Exception as e:
            logger.error(f"ç»Ÿè®¡å‘é‡æ•°é‡å¤±è´¥: {e}")
            raise
    
    def close(self):
        """å…³é—­è¿æ¥"""
        self.qdrant_repo.close()


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="RAGæ•°æ®ç®¡ç†è„šæœ¬")
    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")
    
    # åˆ—å‡ºé›†åˆ
    list_parser = subparsers.add_parser("list", help="åˆ—å‡ºæ‰€æœ‰é›†åˆ")
    
    # åˆ é™¤é›†åˆ
    delete_parser = subparsers.add_parser("delete", help="åˆ é™¤é›†åˆ")
    delete_parser.add_argument("collection_name", help="è¦åˆ é™¤çš„é›†åˆåç§°")
    
    # è·å–é›†åˆä¿¡æ¯
    info_parser = subparsers.add_parser("info", help="è·å–é›†åˆè¯¦ç»†ä¿¡æ¯")
    info_parser.add_argument("collection_name", help="é›†åˆåç§°")
    
    # å¤‡ä»½é›†åˆä¿¡æ¯
    backup_parser = subparsers.add_parser("backup", help="å¤‡ä»½é›†åˆä¿¡æ¯")
    backup_parser.add_argument("--output", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    
    # åˆ›å»ºé›†åˆ
    create_parser = subparsers.add_parser("create", help="åˆ›å»ºæ–°é›†åˆ")
    create_parser.add_argument("collection_name", help="é›†åˆåç§°")
    create_parser.add_argument("--vector-size", type=int, default=1536, help="å‘é‡ç»´åº¦ï¼ˆé»˜è®¤: 1536ï¼‰")
    
    # ç»Ÿè®¡å‘é‡æ•°é‡
    count_parser = subparsers.add_parser("count", help="ç»Ÿè®¡é›†åˆä¸­çš„å‘é‡æ•°é‡")
    count_parser.add_argument("collection_name", help="é›†åˆåç§°")
    
    # æ—¥å¿—çº§åˆ«
    parser.add_argument(
        "--log-level", 
        type=str, 
        default="INFO",
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        help="æ—¥å¿—çº§åˆ«ï¼ˆé»˜è®¤: INFOï¼‰"
    )
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    logger.remove()
    logger.add(sys.stderr, level=args.log_level)
    
    if not args.command:
        parser.print_help()
        sys.exit(1)
    
    # åˆ›å»ºç®¡ç†å™¨
    manager = RAGDataManager()
    
    try:
        if args.command == "list":
            await manager.list_collections()
        
        elif args.command == "delete":
            success = await manager.delete_collection(args.collection_name)
            sys.exit(0 if success else 1)
        
        elif args.command == "info":
            info = await manager.get_collection_info(args.collection_name)
            sys.exit(0 if info else 1)
        
        elif args.command == "backup":
            output_file = await manager.backup_collection_info(args.output)
            logger.info(f"å¤‡ä»½å®Œæˆ: {output_file}")
        
        elif args.command == "create":
            success = await manager.create_collection(
                args.collection_name, 
                args.vector_size
            )
            sys.exit(0 if success else 1)
        
        elif args.command == "count":
            count = await manager.count_vectors(args.collection_name)
            logger.info(f"å‘é‡æ•°é‡: {count}")
    
    except Exception as e:
        logger.error(f"æ‰§è¡Œå‘½ä»¤æ—¶å‡ºé”™: {e}")
        sys.exit(1)
    
    finally:
        manager.close()


if __name__ == "__main__":
    asyncio.run(main())
