#!/usr/bin/env python3
"""
RAGç´¢å¼•æ„å»ºè„šæœ¬
ç”¨äºæ‰¹é‡å¤„ç†æ–‡æ¡£å¹¶å»ºç«‹å‘é‡ç´¢å¼•
"""
import os
import sys
import asyncio
import argparse
from pathlib import Path
from typing import List, Dict, Any
import time
from loguru import logger

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from app.core.config import get_settings
from app.services.rag_service import RAGService
from app.schemas.rag import IndexRequest, DocumentMetadata


class RAGIndexBuilder:
    """RAGç´¢å¼•æ„å»ºå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ„å»ºå™¨"""
        self.settings = get_settings()
        self.rag_service = RAGService(self.settings)
        self.stats = {
            "total_files": 0,
            "processed_files": 0,
            "failed_files": 0,
            "total_chunks": 0,
            "start_time": None,
            "end_time": None
        }
    
    async def build_index_from_directory(
        self, 
        directory: Path, 
        course_id: str,
        collection_name: str = None,
        file_pattern: str = "*.md"
    ) -> Dict[str, Any]:
        """ä»ç›®å½•æ‰¹é‡æ„å»ºç´¢å¼•"""
        self.stats["start_time"] = time.time()
        
        logger.info(f"å¼€å§‹å¤„ç†ç›®å½•: {directory}")
        logger.info(f"è¯¾ç¨‹ID: {course_id}")
        logger.info(f"æ–‡ä»¶æ¨¡å¼: {file_pattern}")
        logger.info(f"é›†åˆåç§°: {collection_name or self.settings.qdrant_collection_name}")
        
        # æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…çš„æ–‡ä»¶
        files = list(directory.glob(file_pattern))
        if not files:
            logger.warning(f"åœ¨ç›®å½• {directory} ä¸­æœªæ‰¾åˆ°åŒ¹é… {file_pattern} çš„æ–‡ä»¶")
            return self.stats
        
        self.stats["total_files"] = len(files)
        logger.info(f"æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶å¾…å¤„ç†")
        
        # å¤„ç†æ¯ä¸ªæ–‡ä»¶
        for i, file_path in enumerate(files, 1):
            logger.info(f"å¤„ç†æ–‡ä»¶ {i}/{len(files)}: {file_path.name}")
            
            try:
                await self._process_file(file_path, course_id, collection_name)
                self.stats["processed_files"] += 1
                logger.info(f"âœ… æ–‡ä»¶å¤„ç†æˆåŠŸ: {file_path.name}")
            except Exception as e:
                self.stats["failed_files"] += 1
                logger.error(f"âŒ æ–‡ä»¶å¤„ç†å¤±è´¥: {file_path.name} - {e}")
        
        self.stats["end_time"] = time.time()
        self._print_summary()
        
        return self.stats
    
    async def _process_file(
        self, 
        file_path: Path, 
        course_id: str,
        collection_name: str = None
    ):
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        try:
            # è¯»å–æ–‡ä»¶å†…å®¹
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ç”Ÿæˆææ–™IDï¼ˆåŸºäºæ–‡ä»¶åï¼‰
            material_id = f"material_{file_path.stem}"
            
            # æ„å»ºå…ƒæ•°æ®
            metadata = DocumentMetadata(
                course_id=course_id,
                course_material_id=material_id,
                course_material_name=file_path.stem,
                file_path=str(file_path),
                file_size=len(content.encode('utf-8'))
            )
            
            # æ„å»ºç´¢å¼•è¯·æ±‚
            request = IndexRequest(
                file_content=content,
                metadata=metadata,
                collection_name=collection_name
            )
            
            # æ‰§è¡Œç´¢å¼•å»ºç«‹
            response = await self.rag_service.build_index(request)
            
            if response.success:
                self.stats["total_chunks"] += response.chunk_count
                logger.debug(f"æ–‡ä»¶ {file_path.name} ç”Ÿæˆäº† {response.chunk_count} ä¸ªæ–‡æœ¬å—")
            else:
                raise Exception(response.message)
        
        except Exception as e:
            logger.error(f"å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
            raise
    
    def _print_summary(self):
        """æ‰“å°å¤„ç†æ‘˜è¦"""
        duration = self.stats["end_time"] - self.stats["start_time"]
        
        logger.info("=" * 60)
        logger.info("ğŸ“Š ç´¢å¼•æ„å»ºæ‘˜è¦")
        logger.info("=" * 60)
        logger.info(f"æ€»æ–‡ä»¶æ•°: {self.stats['total_files']}")
        logger.info(f"æˆåŠŸå¤„ç†: {self.stats['processed_files']}")
        logger.info(f"å¤„ç†å¤±è´¥: {self.stats['failed_files']}")
        logger.info(f"æ€»æ–‡æœ¬å—: {self.stats['total_chunks']}")
        logger.info(f"å¤„ç†æ—¶é—´: {duration:.2f} ç§’")
        
        if self.stats["processed_files"] > 0:
            avg_time = duration / self.stats["processed_files"]
            logger.info(f"å¹³å‡å¤„ç†æ—¶é—´: {avg_time:.2f} ç§’/æ–‡ä»¶")
        
        success_rate = (self.stats["processed_files"] / self.stats["total_files"]) * 100
        logger.info(f"æˆåŠŸç‡: {success_rate:.1f}%")
        logger.info("=" * 60)


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="RAGç´¢å¼•æ„å»ºè„šæœ¬")
    parser.add_argument(
        "directory", 
        type=str, 
        help="åŒ…å«æ–‡æ¡£çš„ç›®å½•è·¯å¾„"
    )
    parser.add_argument(
        "--course-id", 
        type=str, 
        required=True,
        help="è¯¾ç¨‹ID"
    )
    parser.add_argument(
        "--collection-name", 
        type=str, 
        help="Qdranté›†åˆåç§°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„åç§°ï¼‰"
    )
    parser.add_argument(
        "--pattern", 
        type=str, 
        default="*.md",
        help="æ–‡ä»¶åŒ¹é…æ¨¡å¼ï¼ˆé»˜è®¤: *.mdï¼‰"
    )
    parser.add_argument(
        "--log-level", 
        type=str, 
        default="INFO",
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        help="æ—¥å¿—çº§åˆ«ï¼ˆé»˜è®¤: INFOï¼‰"
    )
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    logger.remove()
    logger.add(sys.stderr, level=args.log_level)
    
    # éªŒè¯ç›®å½•
    directory = Path(args.directory)
    if not directory.exists():
        logger.error(f"ç›®å½•ä¸å­˜åœ¨: {directory}")
        sys.exit(1)
    
    if not directory.is_dir():
        logger.error(f"è·¯å¾„ä¸æ˜¯ç›®å½•: {directory}")
        sys.exit(1)
    
    # åˆ›å»ºæ„å»ºå™¨å¹¶æ‰§è¡Œ
    builder = RAGIndexBuilder()
    
    try:
        stats = await builder.build_index_from_directory(
            directory=directory,
            course_id=args.course_id,
            collection_name=args.collection_name,
            file_pattern=args.pattern
        )
        
        # æ ¹æ®ç»“æœè®¾ç½®é€€å‡ºç 
        if stats["failed_files"] == 0:
            logger.info("ğŸ‰ æ‰€æœ‰æ–‡ä»¶å¤„ç†æˆåŠŸï¼")
            sys.exit(0)
        elif stats["processed_files"] > 0:
            logger.warning("âš ï¸ éƒ¨åˆ†æ–‡ä»¶å¤„ç†å¤±è´¥")
            sys.exit(1)
        else:
            logger.error("âŒ æ‰€æœ‰æ–‡ä»¶å¤„ç†å¤±è´¥")
            sys.exit(2)
    
    except Exception as e:
        logger.error(f"ç´¢å¼•æ„å»ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        sys.exit(3)


if __name__ == "__main__":
    asyncio.run(main())
